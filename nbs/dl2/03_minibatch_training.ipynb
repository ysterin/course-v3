{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_02 import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=1786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = x_train.shape\n",
    "c = y_train.max()+1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will need to compute the softmax of our activations. This is defined by:\n",
    "\n",
    "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$\n",
    "\n",
    "or more concisely:\n",
    "\n",
    "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum_{0 \\leq j \\leq n-1} e^{x_{j}}}$$ \n",
    "\n",
    "In practice, we will need the log of the softmax when we calculate the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_pred = log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
    "\n",
    "$$ -\\sum x\\, \\log p(x) $$\n",
    "\n",
    "But since our $x$s are 1-hot encoded, this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done using numpy-style [integer array indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html#integer-array-indexing). Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2729, -2.1288, -2.1847], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[[0,1,2], [5,0,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=2081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target): return -input[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nll(sm_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3063, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the formula \n",
    "\n",
    "$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$ \n",
    "\n",
    "gives a simplification when we compute the log softmax, which was previously defined as `(x.exp()/(x.exp().sum(-1,keepdim=True))).log()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.exp().sum(-1,keepdim=True).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(nll(log_softmax(pred), y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the [LogSumExp trick](https://en.wikipedia.org/wiki/LogSumExp). The idea is to use the following formula:\n",
    "\n",
    "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
    "\n",
    "where a is the maximum of the $x_{j}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    m = x.max(-1)[0]\n",
    "    return m + (x-m[:,None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we will avoid an overflow when taking the exponential of a big activation. In PyTorch, this is already implemented for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(logsumexp(pred), pred.logsumexp(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can use it for our `log_softmax` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.logsumexp(-1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(nll(log_softmax(pred), y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use PyTorch's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(F.nll_loss(F.log_softmax(pred, -1), y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, `F.log_softmax` and `F.nll_loss` are combined in one optimized function, `F.cross_entropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(F.cross_entropy(pred, y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically the training loop repeats over the following steps:\n",
    "- get the output of the model on a batch of inputs\n",
    "- compare the output to the labels we have and compute a loss\n",
    "- calculate the gradients of the loss with respect to every parameter of the model\n",
    "- update said parameters with those gradients to make them a little bit better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=2542)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.1150, -0.1813,  0.0926, -0.0294,  0.1180,  0.0461, -0.1432, -0.0125,\n",
       "         -0.1431,  0.2216], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=64                  # batch size\n",
    "\n",
    "xb = x_train[0:bs]     # a mini-batch from x\n",
    "preds = model(xb)      # predictions\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2992, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1406)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5   # learning rate\n",
    "epochs = 1 # how many epochs to train for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "#         set_trace()\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        loss = loss_func(model(xb), yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias   -= l.bias.grad   * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias  .grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1280, grad_fn=<NllLossBackward>), tensor(1.))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using parameters and optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `nn.Module.__setattr__` and move relu to functional:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=2818)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in,nh)\n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "        \n",
    "    def __call__(self, x): return self.l2(F.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name,l in model.named_children(): print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=50, bias=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n-1)//bs + 1):\n",
    "            start_i = i*bs\n",
    "            end_i = start_i+bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            loss = loss_func(model(xb), yb)\n",
    "\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= p.grad * lr\n",
    "                model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1296, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, PyTorch overrides the `__setattr__` function in `nn.Module` so that the submodules you define are properly registered as parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyModule():\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in,nh)\n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "        \n",
    "    def __setattr__(self,k,v):\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k,v)\n",
    "        \n",
    "    def __repr__(self): return f'{self._modules}'\n",
    "    \n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            for p in l.parameters(): yield p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = DummyModule(m,nh,10)\n",
    "mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([50, 784]),\n",
       " torch.Size([50]),\n",
       " torch.Size([10, 50]),\n",
       " torch.Size([10])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o.shape for o in mdl.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the original `layers` approach, but we have to register the modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=2997)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.ModuleList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.ModuleList` does this for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3173)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SequentialModel(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1011, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Sequential` is a convenient class which does the same as the above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2284, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Sequential??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replace our previous manually coded optimization step:\n",
    "\n",
    "```python\n",
    "with torch.no_grad():\n",
    "    for p in model.parameters(): p -= p.grad * lr\n",
    "    model.zero_grad()\n",
    "```\n",
    "\n",
    "and instead use just:\n",
    "\n",
    "```python\n",
    "opt.step()\n",
    "opt.zero_grad()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3278)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5): self.params,self.lr=list(params),lr\n",
    "        \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0560, grad_fn=<NllLossBackward>), tensor(1.))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch already provides this exact functionality in `optim.SGD` (it also handles stuff like momentum, which we'll look at later - except we'll be doing it in a more flexible way!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.SGD.step??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3355, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1220, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomized tests can be very useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3442)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc>0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clunky to iterate through minibatches of x and y values separately:\n",
    "\n",
    "```python\n",
    "    xb = x_train[start_i:end_i]\n",
    "    yb = y_train[start_i:end_i]\n",
    "```\n",
    "\n",
    "Instead, let's do these two steps together, by introducing a `Dataset` class:\n",
    "\n",
    "```python\n",
    "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3578)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i],self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
    "assert len(train_ds)==len(x_train)\n",
    "assert len(valid_ds)==len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = train_ds[0:5]\n",
    "assert xb.shape==(5,28*28)\n",
    "assert yb.shape==(5,)\n",
    "xb,yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        xb,yb = train_ds[i*bs : i*bs+bs]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1134, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, our loop iterated over batches (xb, yb) like this:\n",
    "\n",
    "```python\n",
    "for i in range((n-1)//bs + 1):\n",
    "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
    "    ...\n",
    "```\n",
    "\n",
    "Let's make our loop much cleaner, using a data loader:\n",
    "\n",
    "```python\n",
    "for xb,yb in train_dl:\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3674)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, bs): self.ds,self.bs = ds,bs\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = next(iter(valid_dl))\n",
    "assert xb.shape==(bs,28*28)\n",
    "assert yb.shape==(bs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb,yb in train_dl:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1550, grad_fn=<NllLossBackward>), tensor(0.9531))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our training set to be in a random order, and that order should differ each iteration. But the validation set shouldn't be randomized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3942)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, bs, shuffle=False):\n",
    "        self.n,self.bs,self.shuffle = len(ds),bs,shuffle\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
    "        for i in range(0, self.n, self.bs): yield self.idxs[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ds = Dataset(*train_ds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Sampler(small_ds,3,False)\n",
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([6, 7, 0]), tensor([1, 5, 9]), tensor([8, 2, 4]), tensor([3])]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Sampler(small_ds,3,True)\n",
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return torch.stack(xs),torch.stack(ys)\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, sampler, collate_fn=collate):\n",
    "        self.ds,self.sampler,self.collate_fn = ds,sampler,collate_fn\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for s in self.sampler: yield self.collate_fn([self.ds[i] for i in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = Sampler(train_ds, bs, shuffle=True)\n",
    "valid_samp = Sampler(valid_ds, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = next(iter(valid_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = next(iter(train_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = next(iter(train_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0778, grad_fn=<NllLossBackward>), tensor(0.9844))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "\n",
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.0254,  0.0026, -0.0166,  ..., -0.0067, -0.0140, -0.0152],\n",
       "                      [-0.0090,  0.0233, -0.0129,  ..., -0.0164,  0.0111, -0.0168],\n",
       "                      [ 0.0356,  0.0018,  0.0087,  ..., -0.0032,  0.0225, -0.0329],\n",
       "                      ...,\n",
       "                      [-0.0192, -0.0159,  0.0318,  ..., -0.0295,  0.0144, -0.0329],\n",
       "                      [ 0.0324,  0.0219,  0.0287,  ...,  0.0340, -0.0336,  0.0025],\n",
       "                      [-0.0297,  0.0148,  0.0314,  ...,  0.0313, -0.0229, -0.0103]])),\n",
       "             ('0.bias',\n",
       "              tensor([ 0.1005, -0.1221, -0.0499,  0.0996,  0.0803, -0.2218,  0.0148,  0.0219,\n",
       "                      -0.1447, -0.0085, -0.0384,  0.2416,  0.1477, -0.2077, -0.2386, -0.0112,\n",
       "                       0.0165, -0.0685,  0.1614,  0.1556,  0.2444,  0.0608,  0.1991,  0.1209,\n",
       "                       0.0804, -0.1974, -0.1334,  0.1386, -0.1371,  0.2080,  0.0086,  0.1268,\n",
       "                       0.0308, -0.0622, -0.1447,  0.1971, -0.0779, -0.0286,  0.1929, -0.0506,\n",
       "                       0.0426,  0.0565,  0.1895, -0.1130,  0.0637,  0.1176, -0.0825,  0.3206,\n",
       "                      -0.0293, -0.0405])),\n",
       "             ('2.weight',\n",
       "              tensor([[-2.0764e-01, -1.2074e-01,  4.4967e-01, -1.8253e-01, -6.3243e-02,\n",
       "                        1.0670e-01,  1.2115e-01,  2.7344e-01,  7.3380e-01,  2.0143e-01,\n",
       "                       -9.0131e-02,  2.3974e-02, -3.0820e-01, -7.9154e-02,  2.3651e-03,\n",
       "                       -9.2778e-02,  2.4252e-02,  5.1795e-01, -1.8605e-01, -4.4570e-01,\n",
       "                        9.3318e-02, -1.9487e-01,  4.1605e-01,  3.5038e-01,  1.9688e-01,\n",
       "                        1.7958e-01,  1.5379e-01,  4.6634e-03,  2.1227e-01, -1.7249e-01,\n",
       "                        1.1463e-01, -1.9972e-01, -1.2011e-01,  2.5055e-01,  5.0910e-01,\n",
       "                       -2.5108e-01,  6.5499e-01,  1.4503e-02,  3.5138e-01,  1.7311e-01,\n",
       "                       -5.7797e-02, -2.9441e-01, -2.6269e-01,  2.1783e-01, -1.0983e-01,\n",
       "                       -2.3585e-01, -3.5903e-01, -1.2076e-01, -6.0166e-01, -7.2347e-01],\n",
       "                      [ 6.1522e-01, -1.5549e-01,  1.3923e-01,  2.9400e-01,  4.5930e-01,\n",
       "                       -2.9890e-01, -5.4623e-01,  2.7219e-01, -3.2633e-01,  2.4498e-02,\n",
       "                       -1.7098e-01, -5.3729e-01, -2.2163e-01, -3.5643e-01, -2.1408e-01,\n",
       "                        1.9223e-01,  4.4335e-02, -2.0265e-01, -7.0905e-02, -5.5237e-01,\n",
       "                       -2.7345e-01,  1.0888e-02,  1.2849e-02, -1.0270e-01, -2.9634e-01,\n",
       "                       -2.2331e-01, -2.5927e-01, -1.9728e-01, -4.1498e-01, -3.3175e-01,\n",
       "                       -8.6913e-02,  3.1122e-01, -6.7906e-02, -3.3436e-01, -1.8613e-01,\n",
       "                       -1.7711e-01, -1.9419e-01,  5.8821e-03, -2.4925e-01, -1.3143e-01,\n",
       "                        3.3763e-01,  3.7411e-01, -2.4223e-01, -2.6528e-02,  7.6971e-01,\n",
       "                        1.2276e-01, -8.8116e-02,  8.1409e-01, -1.5282e-01,  6.9920e-01],\n",
       "                      [ 3.1132e-01,  2.5458e-01, -5.0631e-01,  4.5012e-02, -2.8804e-01,\n",
       "                        1.3393e-01, -1.6536e-01,  4.2429e-01,  4.8370e-01, -8.7011e-02,\n",
       "                        1.8517e-01,  9.7126e-01,  2.6301e-01, -3.9612e-01,  3.8222e-01,\n",
       "                        5.5555e-01, -3.2765e-02,  4.6162e-01,  2.1955e-01,  3.2168e-01,\n",
       "                       -8.0971e-02,  6.2168e-01, -6.9336e-02,  2.3828e-01,  6.1710e-01,\n",
       "                        1.1630e-01, -5.1320e-02, -3.1980e-01,  5.1201e-02,  4.3008e-01,\n",
       "                       -4.5309e-02,  5.2513e-02, -5.3257e-01, -4.5186e-01,  5.0163e-02,\n",
       "                       -2.3669e-01, -2.5069e-02,  3.5370e-01, -4.1218e-01, -2.9382e-01,\n",
       "                       -1.3682e-01,  8.6360e-01, -7.6521e-02, -1.4831e-01, -1.8129e-01,\n",
       "                        4.3466e-01, -3.0548e-01, -4.9517e-01, -7.7542e-01,  2.2581e-01],\n",
       "                      [-2.9923e-01,  3.0411e-01,  4.9633e-02, -4.5174e-01, -2.4666e-01,\n",
       "                       -4.7751e-02,  2.7201e-01,  2.7302e-01, -9.0503e-02,  1.5280e-01,\n",
       "                        2.7526e-01, -1.9885e-01,  4.8066e-01, -6.0932e-01,  3.2430e-01,\n",
       "                       -1.8015e-01,  2.5548e-01, -6.1064e-02,  7.2032e-02, -2.2822e-01,\n",
       "                       -2.6681e-01, -1.2157e-01, -5.9804e-02, -1.4742e-01,  4.7947e-03,\n",
       "                       -1.5445e-01,  1.8227e-01, -1.1661e-01, -6.9514e-03,  2.4927e-01,\n",
       "                       -9.5525e-02, -3.5209e-01,  1.3927e-01, -4.6779e-01, -4.3475e-01,\n",
       "                       -3.7012e-01,  3.3236e-01,  5.6982e-01, -2.9501e-01, -3.9606e-01,\n",
       "                       -2.9657e-02,  3.8209e-02, -3.7740e-01,  9.3488e-02, -2.1164e-01,\n",
       "                        7.0085e-01,  4.6849e-01, -4.2898e-01,  8.9411e-01,  3.3237e-01],\n",
       "                      [ 1.0686e-01,  1.1562e-01,  6.6241e-02,  7.7432e-01, -4.0424e-01,\n",
       "                        1.2812e-01, -7.5033e-01, -1.6608e-01, -1.7757e-01, -2.7254e-03,\n",
       "                        3.2581e-01,  3.8838e-01, -4.7082e-01,  4.6336e-01, -6.9802e-01,\n",
       "                       -1.9175e-01, -3.3642e-01, -1.9128e-01, -3.6042e-01,  4.2365e-01,\n",
       "                       -3.2535e-01, -3.5761e-01, -4.7888e-01, -2.8269e-01, -2.0575e-01,\n",
       "                       -3.1026e-01, -9.9172e-02, -6.1516e-01,  2.6728e-01, -3.0206e-01,\n",
       "                       -1.1243e-01,  3.7436e-01, -2.8184e-01,  2.1506e-01, -2.4290e-01,\n",
       "                        6.4476e-01, -2.2837e-01, -6.1322e-01,  5.1971e-01, -2.7589e-02,\n",
       "                        1.9926e-01, -4.2389e-01,  6.4698e-01, -3.5440e-01,  6.1008e-01,\n",
       "                       -8.5512e-02,  3.8883e-02, -1.9146e-01,  3.5483e-01, -4.4896e-01],\n",
       "                      [-5.0277e-01, -3.1770e-01, -4.5049e-01, -9.2326e-01,  3.3257e-01,\n",
       "                       -2.0435e-01,  5.5437e-01, -5.1711e-01, -5.4790e-01,  5.9948e-02,\n",
       "                        1.9371e-01, -2.4363e-01, -1.2618e-01,  2.6965e-01, -3.5133e-01,\n",
       "                       -4.1971e-01,  1.1271e-01, -1.4339e-01,  3.2850e-01,  5.4395e-01,\n",
       "                        8.4634e-01, -2.1680e-01,  1.1230e+00,  1.6818e-01,  3.3898e-01,\n",
       "                        2.0245e-02, -6.0446e-01,  4.2049e-01, -3.1901e-01,  3.0197e-01,\n",
       "                       -5.8275e-03,  3.4347e-02,  8.9128e-01,  2.8991e-01,  1.0893e-01,\n",
       "                       -3.5882e-01,  5.1167e-02,  2.4102e-01,  2.8591e-02, -4.6510e-02,\n",
       "                       -3.4276e-01, -9.3027e-03,  7.0228e-02,  1.3220e-02, -2.9642e-01,\n",
       "                        3.6646e-01, -2.6330e-02,  6.9346e-01,  3.2488e-01, -5.5259e-02],\n",
       "                      [ 1.4983e-01, -1.3678e-01,  2.5069e-01, -2.6876e-01,  2.2433e-01,\n",
       "                        3.3329e-02, -6.2916e-01, -2.6699e-01, -1.7774e-01, -1.2866e-01,\n",
       "                       -4.2125e-01,  4.2866e-01, -3.6127e-01,  3.6644e-01, -1.7024e-01,\n",
       "                        2.3928e-01, -6.6785e-02, -3.1766e-02, -1.6172e-01,  1.1469e-01,\n",
       "                       -2.7087e-01, -1.2031e-01,  1.9360e-01, -1.3036e-01,  1.8013e-01,\n",
       "                       -1.1675e-01, -4.9956e-01,  8.7918e-01,  3.4870e-01,  3.9294e-01,\n",
       "                        1.3357e-01, -1.2823e-01,  4.6140e-01,  4.8597e-01,  3.7523e-03,\n",
       "                       -2.6324e-01,  3.5581e-01, -7.8639e-01,  2.2657e-01, -6.2176e-02,\n",
       "                        5.2148e-01, -3.8179e-01, -4.9211e-01, -3.3589e-02, -1.4276e-01,\n",
       "                       -4.2634e-01, -3.0541e-01, -9.8018e-02, -5.1392e-01,  9.2017e-02],\n",
       "                      [-1.1966e-02, -1.7212e-01,  5.9486e-02,  4.6224e-01,  1.9781e-01,\n",
       "                       -4.1376e-01,  2.6573e-01,  2.8000e-01, -1.6399e-01,  6.0257e-02,\n",
       "                       -4.4730e-01, -1.8839e-01,  8.4318e-01, -3.5798e-01, -2.1367e-01,\n",
       "                        5.7834e-01,  2.8813e-01, -8.4500e-02,  4.2652e-01, -4.0296e-01,\n",
       "                        5.1988e-01,  6.8456e-01, -8.2134e-02,  7.9077e-02, -4.0686e-01,\n",
       "                       -3.4524e-01,  3.2321e-01, -7.7016e-02, -5.6480e-01,  3.3177e-01,\n",
       "                        3.7988e-02,  1.2150e-01, -5.5668e-01, -4.8855e-01, -1.1669e-01,\n",
       "                        6.4899e-01, -2.6821e-01,  1.1104e-01,  5.0270e-01, -7.9501e-02,\n",
       "                       -2.6157e-01,  6.0862e-01,  5.8151e-01,  7.0991e-02,  2.6175e-02,\n",
       "                       -2.5784e-01,  1.0906e-01, -1.5640e-01, -3.6768e-01, -2.8919e-01],\n",
       "                      [-1.8410e-01,  6.3587e-02, -4.1114e-01,  9.6240e-02, -1.0591e-01,\n",
       "                        2.9493e-01,  3.4196e-01, -4.0520e-01, -2.2358e-02,  1.3145e-01,\n",
       "                        4.6764e-01, -6.2534e-01, -3.9465e-01,  7.4931e-01,  1.8029e-01,\n",
       "                        3.5375e-01, -1.2444e-02, -2.4840e-01, -2.6040e-01,  9.8421e-02,\n",
       "                        1.2275e-01, -1.8269e-02, -7.1485e-01, -3.8262e-01, -4.6542e-01,\n",
       "                        3.4956e-01,  2.5422e-01, -1.6212e-01, -7.8314e-02, -3.5847e-01,\n",
       "                       -4.3872e-02, -4.2589e-01,  1.9301e-01,  2.0468e-01,  6.1280e-01,\n",
       "                       -4.5725e-01, -2.1918e-01,  2.8323e-01, -4.5773e-01, -3.3380e-02,\n",
       "                       -3.7887e-01, -1.4816e-01, -4.5519e-01,  2.2741e-01, -6.7970e-01,\n",
       "                       -4.2386e-01,  3.4871e-01, -3.4459e-01, -2.0700e-01,  6.0071e-01],\n",
       "                      [-3.6800e-01, -5.0199e-02,  2.4442e-01,  5.7254e-01,  2.8057e-01,\n",
       "                        1.7954e-01,  3.0613e-01, -2.6972e-01,  1.4163e-01, -1.4764e-01,\n",
       "                       -4.4322e-01, -1.8741e-01,  4.0975e-01,  7.8287e-02,  4.3696e-01,\n",
       "                       -7.1466e-01, -5.4472e-04, -7.0787e-02, -2.4308e-01,  3.6091e-01,\n",
       "                       -3.7062e-01, -4.3055e-01, -1.3787e-01, -3.3269e-01, -3.0478e-01,\n",
       "                        1.5851e-01,  5.5036e-01, -5.6883e-01,  1.9074e-01, -2.2089e-01,\n",
       "                        1.2690e-01,  4.2969e-01, -1.2391e-01,  3.9982e-02, -1.0150e-01,\n",
       "                        5.1715e-01, -3.1061e-01, -1.4114e-01, -3.5930e-01,  6.1036e-01,\n",
       "                        7.8450e-02, -6.7236e-01,  2.8026e-01,  2.8824e-01, -2.3873e-02,\n",
       "                       -9.9445e-02,  2.2823e-01,  9.9968e-02,  5.9352e-01, -5.0159e-01]])),\n",
       "             ('2.bias',\n",
       "              tensor([-0.2392,  0.0769, -0.1946,  0.0131,  0.1498,  0.3174, -0.0160,  0.0135,\n",
       "                       0.0120, -0.1030]))])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=4171)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 6 required positional arguments: 'epochs', 'model', 'loss_func', 'opt', 'train_dl', and 'valid_dl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-7c5441fd45b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 6 required positional arguments: 'epochs', 'model', 'loss_func', 'opt', 'train_dl', and 'valid_dl'"
     ]
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch's defaults work fine for most things however:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True)\n",
    "valid_dl = DataLoader(valid_ds, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 6 required positional arguments: 'epochs', 'model', 'loss_func', 'opt', 'train_dl', and 'valid_dl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-24090b23970e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 6 required positional arguments: 'epochs', 'model', 'loss_func', 'opt', 'train_dl', and 'valid_dl'"
     ]
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "\n",
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that PyTorch's `DataLoader`, if you pass `num_workers`, will use multiple threads to call your `Dataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You **always** should also have a [validation set](http://www.fast.ai/2017/11/13/validation-sets/), in order to identify if you are overfitting.\n",
    "\n",
    "We will calculate and print the validation loss at the end of each epoch.\n",
    "\n",
    "(Note that we always call `model.train()` before training, and `model.eval()` before inference, because these are used by layers such as `nn.BatchNorm2d` and `nn.Dropout` to ensure appropriate behaviour for these different phases.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=4260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        # Handle batchnorm / dropout\n",
    "        model.train()\n",
    "#         print(model.training)\n",
    "        for xb,yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "#         print(model.training)\n",
    "        with torch.no_grad():\n",
    "            tot_loss,tot_acc = 0.,0.\n",
    "            for xb,yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                tot_loss += loss_func(pred, yb)\n",
    "                tot_acc  += accuracy (pred,yb)\n",
    "        nv = len(valid_dl)\n",
    "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
    "    return tot_loss/nv, tot_acc/nv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question*: Are these validation results correct if batch size varies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_dls` returns dataloaders for the training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our whole process of obtaining the data loaders and fitting the model can be run in 3 lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.1754) tensor(0.9491)\n",
      "1 tensor(0.1573) tensor(0.9526)\n",
      "2 tensor(0.1064) tensor(0.9690)\n",
      "3 tensor(0.1408) tensor(0.9570)\n",
      "4 tensor(0.1005) tensor(0.9708)\n"
     ]
    }
   ],
   "source": [
    "train_dl,valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model,opt = get_model()\n",
    "loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc>0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File \"notebook2script.py\", line 55\r\n",
      "    fname_out = f'nb_{fname.stem.split(\"_\")[0]}.py'\r\n",
      "                                                  ^\r\n",
      "SyntaxError: invalid syntax\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py 03_minibatch_training.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
